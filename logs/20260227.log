{"ts": "2026-02-27 01:59:37,655", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "student_mid", "metadata": "{\"hostname\": \"as03r1b02\", \"pid\": 2712936, \"timestamp\": 1772153976.8919554, \"git_commit\": \"1aae81d\", \"model\": \"Qwen/Qwen2.5-7B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36991494\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-27 01:59:37,655", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-7B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype auto --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-27 01:59:38,810", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "student_small", "metadata": "{\"hostname\": \"as03r1b04\", \"pid\": 3330280, \"timestamp\": 1772153977.9937963, \"git_commit\": \"1aae81d\", \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36991495\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-27 01:59:38,813", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-1.5B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype auto --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-27 01:59:39,982", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "student_small", "metadata": "{\"hostname\": \"as02r3b09\", \"pid\": 277680, \"timestamp\": 1772153979.1603534, \"git_commit\": \"1aae81d\", \"model\": \"Qwen/Qwen2.5-1.5B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36989625\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-27 01:59:39,985", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-1.5B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype auto --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-27 01:59:40,368", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "student_mid", "metadata": "{\"hostname\": \"as02r3b06\", \"pid\": 3102167, \"timestamp\": 1772153979.5651498, \"git_commit\": \"1aae81d\", \"model\": \"Qwen/Qwen2.5-7B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36989624\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-27 01:59:40,371", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-7B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype auto --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-27 07:15:52,087", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "teacher", "metadata": "{\"hostname\": \"as07r4b12\", \"pid\": 2610394, \"timestamp\": 1772172951.2266054, \"git_commit\": \"1aae81d\", \"model\": \"Qwen/Qwen2.5-14B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36975320\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-27 07:16:01,053", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-14B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype auto --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-27 07:34:30,830", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "teacher", "metadata": "{\"hostname\": \"as07r2b18\", \"pid\": 1767513, \"timestamp\": 1772174069.9573407, \"git_commit\": \"1aae81d\", \"model\": \"Qwen/Qwen2.5-14B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36980381\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}, {\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-27 07:34:30,849", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-14B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype auto --swap-space 4 --max-num-seqs 256 --seed 42"}
