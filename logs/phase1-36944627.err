unload PYTHON/3.12.1 (PATH, MANPATH, LD_LIBRARY_PATH, LIBRARY_PATH,
PKG_CONFIG_PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, PYTHONHOME, PYTHONPATH) 
unload SQLITE3/3.45.2 (PATH)
unload HDF5/1.14.1-2 (PATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH, HDF5_DIR, HDF5_ROOT,CFLAGS, CPPFLAGS, LDFLAGS) 
remove mkl/2023.2.0 (LD_LIBRARY_PATH)
remove impi/2021.10.0 (PATH, MANPATH, LD_LIBRARY_PATH)
Set INTEL compilers as MPI wrappers backend
load impi/2021.10.0 (PATH, MANPATH, LD_LIBRARY_PATH)
load mkl/2023.2.0 (LD_LIBRARY_PATH)
load SQLITE3/3.45.2 (PATH)
load HDF5/1.14.1-2 (PATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH, HDF5_DIR, HDF5_ROOT,CFLAGS, CPPFLAGS, LDFLAGS) 
load PYTHON/3.12.1 (PATH, MANPATH, LD_LIBRARY_PATH, LIBRARY_PATH,
PKG_CONFIG_PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, PYTHONHOME, PYTHONPATH) 
unload SQLITE3/3.45.2 (PATH)
load SQLITE3/3.45.2 (PATH)
/home/bsc/bsc381408/.venvs/tfg/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/bsc/bsc381408/.venvs/tfg/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[0;36m(EngineCore_DP0 pid=3510379)[0;0m /home/bsc/bsc381408/.venvs/tfg/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py:52: UserWarning: Failed to get the IP address, using 0.0.0.0 by default.The value can be set by the environment variable VLLM_HOST_IP or HOST_IP.
[0;36m(EngineCore_DP0 pid=3510379)[0;0m   distributed_init_method = get_distributed_init_method(get_ip(), get_open_port())
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/8 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards:  12% Completed | 1/8 [00:03<00:26,  3.84s/it]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards:  25% Completed | 2/8 [00:07<00:22,  3.69s/it]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards:  38% Completed | 3/8 [00:09<00:13,  2.73s/it]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards:  50% Completed | 4/8 [00:12<00:12,  3.01s/it]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards:  62% Completed | 5/8 [00:16<00:09,  3.21s/it]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards:  75% Completed | 6/8 [00:19<00:06,  3.33s/it]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards:  88% Completed | 7/8 [00:23<00:03,  3.40s/it]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:26<00:00,  3.43s/it]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:26<00:00,  3.33s/it]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m 
icc: remark #10441: The Intel(R) C++ Compiler Classic (ICC) is deprecated and will be removed from product release in the second half of 2023. The Intel(R) oneAPI DPC++/C++ Compiler (ICX) is the recommended compiler moving forward. Please transition to use this compiler. Use '-diag-disable=10441' to disable this message.
icc: command line warning #10148: option '-Wno-psabi' not supported
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 2/51 [00:00<00:03, 13.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|â–Š         | 4/51 [00:00<00:03, 14.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–        | 6/51 [00:00<00:03, 14.38it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–Œ        | 8/51 [00:00<00:03, 14.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|â–ˆâ–‰        | 10/51 [00:00<00:02, 14.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–Ž       | 12/51 [00:00<00:02, 14.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 14/51 [00:00<00:02, 14.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 16/51 [00:01<00:02, 14.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/51 [00:01<00:02, 14.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 20/51 [00:01<00:02, 14.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 22/51 [00:01<00:01, 14.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 24/51 [00:01<00:01, 14.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 26/51 [00:01<00:01, 14.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/51 [00:01<00:01, 14.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 30/51 [00:02<00:01, 14.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 32/51 [00:02<00:01, 14.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 34/51 [00:02<00:01, 14.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 36/51 [00:02<00:01, 13.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 38/51 [00:02<00:00, 13.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 40/51 [00:02<00:00, 13.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/51 [00:02<00:00, 13.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 44/51 [00:03<00:00, 13.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 46/51 [00:03<00:00, 13.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 48/51 [00:03<00:00, 14.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 50/51 [00:03<00:00, 14.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:03<00:00, 14.34it/s]
[0;36m(EngineCore_DP0 pid=3510379)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   9%|â–Š         | 3/35 [00:00<00:01, 22.54it/s]Capturing CUDA graphs (decode, FULL):  17%|â–ˆâ–‹        | 6/35 [00:00<00:01, 23.23it/s]Capturing CUDA graphs (decode, FULL):  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:00<00:01, 23.45it/s]Capturing CUDA graphs (decode, FULL):  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:00<00:00, 23.66it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/35 [00:00<00:00, 23.71it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:00<00:00, 23.97it/s]Capturing CUDA graphs (decode, FULL):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:00<00:00, 24.02it/s]Capturing CUDA graphs (decode, FULL):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:01<00:00, 23.97it/s]Capturing CUDA graphs (decode, FULL):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:01<00:00, 24.24it/s]Capturing CUDA graphs (decode, FULL):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:01<00:00, 23.64it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [00:01<00:00, 24.61it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:01<00:00, 24.14it/s]
[0;36m(APIServer pid=3510285)[0;0m INFO:     Started server process [3510285]
[0;36m(APIServer pid=3510285)[0;0m INFO:     Waiting for application startup.
[0;36m(APIServer pid=3510285)[0;0m INFO:     Application startup complete.
/home/bsc/bsc381408/.venvs/tfg/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/gpfs/scratch/bsc98/tbsc381408/Tfg-mn5-llm-serving/bench/run_throughput.py", line 130, in <module>
    main()
  File "/gpfs/scratch/bsc98/tbsc381408/Tfg-mn5-llm-serving/bench/run_throughput.py", line 126, in main
    run(args.config)
  File "/gpfs/scratch/bsc98/tbsc381408/Tfg-mn5-llm-serving/bench/run_throughput.py", line 87, in run
    meta = collect_metadata(seed, cfg)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/scratch/bsc98/tbsc381408/Tfg-mn5-llm-serving/utils/reproducibility.py", line 124, in collect_metadata
    "total_memory_mb": round(props.total_mem / (1024 ** 2)),
                             ^^^^^^^^^^^^^^^
AttributeError: 'torch._C._CudaDeviceProperties' object has no attribute 'total_mem'. Did you mean: 'total_memory'?
[rank0]:[W226 06:52:36.200882344 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[0;36m(APIServer pid=3510285)[0;0m INFO:     Shutting down
[0;36m(APIServer pid=3510285)[0;0m INFO:     Waiting for application shutdown.
[0;36m(APIServer pid=3510285)[0;0m INFO:     Application shutdown complete.
