{"ts": "2026-02-25 18:50:30,658", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "dev", "metadata": "{\"hostname\": \"glogin4\", \"pid\": 1088552, \"timestamp\": 1772041830.5665643, \"git_commit\": \"c9dc2d7\", \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\", \"tensor_parallel_size\": 4, \"slurm_job_id\": null, \"gpus\": []}"}
{"ts": "2026-02-25 18:50:30,658", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-0.5B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 4 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype float16 --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-25 18:58:06,209", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "dev", "metadata": "{\"hostname\": \"as04r1b30\", \"pid\": 988412, \"timestamp\": 1772042286.174302, \"git_commit\": \"7eb1d30\", \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36940931\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-25 18:58:06,210", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-0.5B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype float16 --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-25 19:01:47,758", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "dev", "metadata": "{\"hostname\": \"as01r1b13\", \"pid\": 31527, \"timestamp\": 1772042507.7119772, \"git_commit\": \"5b226f9\", \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36941201\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-25 19:01:47,760", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-0.5B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype float16 --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-25 19:50:53,571", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "dev", "metadata": "{\"hostname\": \"as01r1b32\", \"pid\": 3289117, \"timestamp\": 1772045452.810179, \"git_commit\": \"479430f\", \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36942926\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-25 19:50:53,573", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-0.5B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype float16 --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-25 19:53:06,718", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "dev", "metadata": "{\"hostname\": \"as01r1b32\", \"pid\": 3289575, \"timestamp\": 1772045585.9853868, \"git_commit\": \"479430f\", \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36942926\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-25 19:53:06,719", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-0.5B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype float16 --swap-space 4 --max-num-seqs 256 --seed 42"}
{"ts": "2026-02-25 19:55:03,202", "level": "INFO", "logger": "serving.start_server", "message": "Launching vLLM server", "role": "dev", "metadata": "{\"hostname\": \"as01r1b32\", \"pid\": 3290717, \"timestamp\": 1772045702.4887292, \"git_commit\": \"479430f\", \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\", \"tensor_parallel_size\": 1, \"slurm_job_id\": \"36942926\", \"gpus\": [{\"name\": \"NVIDIA H100\", \"vram_mb\": 65247}]}"}
{"ts": "2026-02-25 19:55:25,958", "level": "INFO", "logger": "serving.start_server", "message": "Exec command", "cmd": "vllm serve Qwen/Qwen2.5-0.5B-Instruct --host 0.0.0.0 --port 8000 --tensor-parallel-size 1 --max-model-len 4096 --gpu-memory-utilization 0.9 --dtype float16 --swap-space 4 --max-num-seqs 256 --seed 42"}
